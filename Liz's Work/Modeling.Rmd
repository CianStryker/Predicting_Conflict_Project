---
title: "Modeling"
author: "Liz Masten"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(randomForest)
library(missForest)
library(fastDummies)
library(gtable)
library(gt)
library(gtsummary)
library(tidyverse)
```

```{r}

data <- read_csv("Raw_Data_Liz/Final_Data.csv", col_types = cols(
  .default = col_double(),
  country = col_character(),
  iso2c = col_character(),
  continent = col_character()
))

data <- as.data.frame(data) 

```

```{r}

# The idea was to have all data cleaning done before we started modeling, but imputation is drawing attention to things that need to be taken care of. So this is more data cleaning to make the imputation work and make sense. 

# Create authority_challenge variable from ranges in change outside of -20:20. This is important because (1) change needs to be numeric between -20:20 for the imputation to work, but a factor for the other values; and (2) the values outside of -20:20 represent things that are fundamentally different than in the numeric range. It's just better to have a separate indicator. 

data$change <- as.factor(data$change)

data_2 <- data %>% 
          mutate(authority_challenge = recode_factor(change, 
                                                     "-66" = "1",
                                                     "-77" = "1",
                                                     "0" = "1", 
                                                     "88" = "1",
                                                     "-88" = "1",
                                                     "96" = "1",
                                                     "97" = "1",
                                                     "98" = "1", 
                                                     "99" = "1")) 

data_2$authority_challenge <- ifelse(data_2$authority_challenge =="1", 1, 0)

# Clean up change column to take out values now represented in authority_challenge 

data_3 <- data_2 %>% 
          mutate(change = recode_factor(change,
                                      "-66" = "NA",
                                      "-77" = "NA",
                                      "0" = "NA", 
                                      "88" = "NA",
                                      "-88" = "NA",
                                      "96" = "NA",
                                      "97" = "NA",
                                      "98" = "NA", 
                                      "99" = "NA"))

```


```{r}

# Remove: SF (now represented in authority_challenge)
         #fragment (not coded before 2000)
         #iso2c (represented in country and annoying for imputation)
         #regtrans (now represented in authority_challenge)

data_3 <- data_3 %>% 
          select(-iso2c, -sf, -fragment, -regtrans)

```


```{r}

# Manually change variables for imputation: 

data_3$change <- as.numeric(data_3$change)

data_3$continent <- as.factor(data_3$continent)

data_3$peace_keeping <- as.factor(data_3$peace_keeping)

data_3$change <- as.integer(data_3$change)

data_3$durable <- as.integer(data_3$durable)

data_3$terrorism_kill <- as.integer(data_3$terrorism_kill)

data_3$terrorism_wound <- as.integer(data_3$terrorism_wound)

data_3$state_target <- as.integer(data_3$state_target)

data_3$nonstate_target <- as.integer(data_3$nonstate_target)

data_3$authority_challenge <- as.factor(data_3$authority_challenge)

data_3$xrreg <- as.factor(data_3$xrreg)

data_3$xrcomp <- as.factor(data_3$xrcomp)

data_3$xropen <- as.factor(data_3$xropen)

data_3$parreg <- as.factor(data_3$parreg)

data_3$parcomp <- as.factor(data_3$parcomp)

data_3$xconst <- as.factor(data_3$xconst)

data_3$polity2 <- as.factor(data_3$polity2)

data_3$n_conflict <- as.numeric(data_3$n_conflict)

```

```{r}

# see what's missing: 

p_missing <- unlist(lapply(data_3, function(x) sum(is.na(x))))/nrow(data_3)

sort(p_missing[p_missing > 0], decreasing = TRUE)

# 11/35 variables are missing > 50% of their observations.  

```


```{r, cache=TRUE}

# Impute

set.seed(2020)

# Dummy_cols are necessary because we can't impute factors with more than 53 levels. Obviously our country variable had way more than that. 

dummy_data <- data_3 %>% 
              dummy_cols(select_columns = c("country"),
                        remove_selected_columns = TRUE)

imp_mf <- missForest(dummy_data, variablewise = TRUE, verbose = TRUE, ntree = 100) 

# OOB imputation error est: 

imp_mf$OOBerror

# Here's the data frame

imp_df <- imp_mf$ximp

# Runtime for imputation was ~2 hours. Write as .csv so I never have to run this again. 

imputed_data <- write_csv(imp_df, path = "Raw_Data_Liz/imputed_data.csv")

```


```{r}

rfd <- read_csv("Raw_Data_Liz/imputed_data.csv", col_types = cols(
  .default = col_double(),
  continent = col_character()
))

# Split data for Random Forest model. 

set.seed(2020)

test <- sample(seq(nrow(rfd)), 
                          round(0.2 * nrow(rfd)))

training <- which(!(seq(nrow(rfd)) %in% test))

test_data <- data.frame(rfd[test, ])

# Random forest can't run chr variables? 

rfd$continent <- as.factor(rfd$continent)

```


```{r, cache = TRUE}

# Random Forest

# mtry is defaulted at sqrt of p 

set.seed(2020)

bag.rfd <- randomForest(n_conflict ~ ., data=data.frame(rfd[-test,]),
                              importance =TRUE)

# bag.rfd$importance

```

```{r}

set.seed(2020)
  
# Predict: 
  
rfd.test <- rfd[-training ,"n_conflict"]

# rfd.test <- as.data.frame(rfd.test)

# rfd.test$n_conflict <- as.numeric(rfd.test$n_conflict)

yhat.bag <- predict(bag.rfd, newdata = data.frame(rfd[-training, ]))

# R is throwing weird errors at me when I try to find the MSE, so here's a get-around: 

xx <- (yhat.bag - rfd.test)^2

xx <- as.data.frame(xx)

xx <- as.numeric(xx$n_conflict)

MSE <- mean(xx)

# MSE = [1] 0.01598933 

```

```{r}

# Accuracy 

# rfd.test = test
# yhat.bag = predictions from RF model 

# Make DF of test and predictions. 

check <- data.frame(rfd.test, yhat.bag)

# Make occurance of conflict binary. 

check$real_conflict <- ifelse(check$n_conflict >=1, 1, 0)

check$yhat.bag <- ifelse(check$yhat.bag >= 1, 1, 0)

# Take the difference and count our cases of false negatives, accurate predictions, or false positives. 

final_check_rf <- check %>%
  mutate(diff = real_conflict - yhat.bag) %>%
  count(diff)

final_check_rf

final_check_rf$diff <- as.numeric(final_check_rf$diff)

final_check_rf$n <- as.numeric(final_check_rf$n)

```


```{r}

# Clean for table. 

labels <- c("False Positive", "Accurate", "False Negative")

Percent_Linear <- data.frame(Percent = final_check_rf$n/nrow(test_data)) %>%
  round(digits = 4)


final_check_rf <- data.frame(labels, final_check_rf, Percent_Linear) %>%
  select(-diff)

row1 <- c(NA, NA, NA)
row2 <- c("MSE", unlist(round(MSE, digits = 4)), NA)

final_check_rf <- rbind(final_check_rf, row1,  row2) 

final_check_rf$Percent <- as.numeric(final_check_rf$Percent)

```

```{r}

# Make table

rf_table <- final_check_rf %>%
  gt() %>%
  cols_label("labels" = " ", "n" = "Value") %>%
  tab_header(
    title = "Predicting Civil Conflict",
    subtitle = "Random Forest Prediction Results "
  ) %>%
  fmt_missing(
    columns = 1:3, 
    missing_text = " "
  ) %>%
  cols_align(align = c("center"), columns = TRUE) %>%
  fmt_percent(
    columns = 3, 
    decimals = 2
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(size = 17), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_column_labels(c("n", "Percent"))
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_body(columns = "labels")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_body(columns = c("n", "Percent"))
  ) 


gt::gtsave(rf_table, "Raw_Data_Liz/Random_Forest_Results.png")





```

