---
title: "Modelling"
author: "Cian Stryker"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readr)
library(tidyverse)
library(stats)
library(fastDummies)
library(sjmisc)
library(glmnet)
library(gt)
library(openxlsx)
library(scales)
```


```{r Loading in Imputed Data}

# I load in the imputed version of our final data set here. 

data <- read.csv("Final_Data/imputed_data.csv")

# Since I'll be running models later, I decided to create dummy variables from 
# all of the remaining categorical variables. 

data <- data %>%
  dummy_cols(select_columns = c("year", "continent"), remove_selected_columns = TRUE, remove_first_dummy = FALSE) %>%
  move_columns(n_conflict)

```

```{r}

# Here I wanted to undummy all the variables from the imputed data set so 
# that we could have a "Final" version of our data with imputed values so
# people could see the final results in a more interpretable way. 

Non_Dummy_Data <- data %>%
  gather(key, value, starts_with("country_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "country"), sep = "_") %>%
  select(-value, -start) %>%
  gather(key, value, starts_with("year_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "year"), sep = "_") %>%
  select(-value, -start) %>%
  gather(key, value, starts_with("continent_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "continent"), sep = "_") %>%
  select(-value, -start) %>%
  arrange(country)

Non_Dummy_Data <- Non_Dummy_Data %>%
  select(country, year, continent, everything())

write.xlsx(Non_Dummy_Data, "Final_Data/Non_Dummhy_Imputed_Data.xlsx")


```



```{r Data Splitting}

# Here I make training and test data sets for the modelling

test <- sample(seq(nrow(data)), 
                          round(0.2 * nrow(data)))

training <- which(!(seq(nrow(data)) %in% test))

test_data <- data.frame(data[test, ])

training_data <- data.frame(data[training, ])

```

```{r, Linear Regression}

set.seed(202)

# Pretty simply linear regression using all the predictors available, which
# isn't too computationally hard. 

Model_1 <- lm(data = training_data, n_conflict ~.)

# Then I uset that model to see the predicted results for our
# outcome variable. Since the number of conflicts is a whole number
# I decided to round to the nearest whole number. 

predictions <- predict(Model_1, test_data[,-300]) %>%
  round(digits = 0)

# The model produced negative outcomes which I chose to 
# interpret as "no conflict", so I made them equal to zero. 

predictions[predictions < 0] <- 0

# Figured out the MSE from our model. 

MSE_model_1 <- mean((predictions - test_data[,300])^2)

# Made a dataframe from the predicitons. 

predictions_data <- data.frame(predictions)

# Here I test the accuracy of how the model predicts the exact 
# number of conflicts. In the next code chunck I check if it 
# can just predict whether a conflict occurs or not. 

# table(Truth = test_data$n_conflict, Prediction = predictions_data$predictions)
```

```{r, Accuracy Checking}

set.seed(202)

# Just combined the test data with the predictions. 

check <- data.frame(test_data, predictions_data) 


# Our model is predicting conflict in terms of numbers, but I wanted
# to see whether the model was right in terms of the binary "did civil war
# occur or not" so I made everything either be either 1 conflict occurred
# or 0 conflict did not occur. 

check$real_conflict <- ifelse(check$n_conflict >=1, 1, 0)
check$predict_conflict <- ifelse(check$predictions >= 1, 1, 0)

# Then I take the difference and count our cases of false negatives, 
# accurate predictions, or false positives. 

final_check <- check %>%
  mutate(diff = real_conflict - predict_conflict) %>%
  count(diff)

# Everything below is just cleaning up the results so that I 
# can make a table to present our results. 

labels <- c("False Positive", "Accurate", "False Negative")

Percent_Linear <- data.frame(Percent = final_check$n/nrow(test_data)) %>%
  round(digits = 4)

final_check <- data.frame(labels, final_check, Percent_Linear) %>%
  select(-diff)

row1 <- c(NA, NA, NA)
row2 <- c("MSE", unlist(round(MSE_model_1, digits = 4)), NA)

final_check <- rbind(final_check, row1,  row2) 

final_check$Percent <- as.numeric(final_check$Percent)

linear_results <- final_check %>%
  gt() %>%
  cols_label("labels" = " ", "n" = "Value") %>%
  tab_header(
    title = "Predicting Civil Conflict",
    subtitle = "Linear Model Prediction Results "
  ) %>%
  fmt_missing(
    columns = 1:3, 
    missing_text = " "
  ) %>%
  cols_align(align = c("center"), columns = TRUE) %>%
  fmt_percent(
    columns = 3, 
    decimals = 2
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(size = 17), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_column_labels(c("n", "Percent"))
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_body(columns = "labels")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_body(columns = c("n", "Percent"))
  ) 

gtsave(linear_results, "Images/Linear_Results.png")


```

```{r Ridge Regression}

set.seed(202)


# Here I'm using cross validation to see the best lambda
# to use in our ridge regression. 

ridge_check <- cv.glmnet(x = as.matrix(data[,1:299]),
                         y = as.numeric(data[,300]), 
                         alpha = 0)

opt_lambda <- ridge_check$lambda.min
  
  
# Then I just run the model itself using that lamba

ridge_model <- glmnet(x = as.matrix(training_data[,1:299]),
                      y = as.numeric(training_data[,300]), 
                      lambda = opt_lambda,
                      alpha = 0)

```


```{r Ridge Predictions}

set.seed(202)

# Here I'm just producing the predicted conflict values from the ridge regression. 

ridge_predictions <- predict(ridge_model, s = opt_lambda, newx = as.matrix(test_data[,1:299]))

# MSE check

MSE_model_2 <- mean((ridge_predictions - test_data[,300])^2)

# Rounding and simplifyng the results so that I can create 
# another table. 

ridge_predictions_data <- data.frame(ridge_predictions) %>%
  round(digits = 0)

ridge_predictions_data$X1[ridge_predictions_data$X1 < 0] <- 0

ridge_predictions_data$predictions <- ridge_predictions_data$X1

ridge_predictions_data <- ridge_predictions_data %>%
  select(-X1)

# table(Truth = test_data$n_conflict, Prediction =     ridge_predictions_data$predictions)
```

```{r Ridge Accuracy Check}

set.seed(202)

# Same code from the linear regression but now for the ridge 
# regression. Again I'm only concerned with whether the model 
# predicted a conflict occurred or not, as opposed to correctly 
# predicting the number of conflicts.

ridge_check <- data.frame(test_data, ridge_predictions_data) 


ridge_check$real_conflict <- ifelse(ridge_check$n_conflict >= 1, 1, 0)
ridge_check$predict_conflict <- ifelse(ridge_check$predictions >= 1, 1, 0)


final_ridge_check <- ridge_check %>%
  mutate(diff = real_conflict - predict_conflict) %>%
  count(diff)

final_ridge_check <- data.frame(labels, final_ridge_check)

Percent_Ridge <- data.frame(Percent = final_ridge_check$n/nrow(test_data)) %>%
  round(digits = 4)

final_ridge_check <- data.frame(final_ridge_check, Percent_Ridge) %>%
  select(-diff)

row2_x <- c("MSE", unlist(round(MSE_model_2, digits = 4)), NA)

final_ridge_check <- rbind(final_ridge_check, row1,  row2_x) 

final_ridge_check$Percent <- as.numeric(final_ridge_check$Percent)

ridge_results <- final_ridge_check %>%
  gt() %>%
  cols_label("labels" = " ", "n" = "Value") %>%
  tab_header(
    title = "Predicting Civil Conflict",
    subtitle = "Ridge Regression Prediction Results "
  ) %>%
  fmt_missing(
    columns = 1:3, 
    missing_text = " "
  ) %>%
  cols_align(align = c("center"), columns = TRUE) %>%
  fmt_percent(
    columns = 3, 
    decimals = 2
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(size = 17), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_column_labels(c("n", "Percent"))
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_body(columns = "labels")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_body(columns = c("n", "Percent"))
  ) 

gtsave(ridge_results, "Images/Ridge_Results.png")
```


