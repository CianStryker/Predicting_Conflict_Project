---
title: "Modelling"
author: "Cian Stryker"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readr)
library(tidyverse)
library(stats)
library(fastDummies)
library(sjmisc)
library(glmnet)
library(gt)
library(scales)
```


```{r Loading in Imputed Data}

data <- read.csv("Final_Data/imputed_data.csv")

data <- data %>%
  dummy_cols(select_columns = c("year", "continent"), remove_selected_columns = TRUE, remove_first_dummy = FALSE) %>%
  move_columns(n_conflict)

```


```{r Data Splitting}

#split data

test <- sample(seq(nrow(data)), 
                          round(0.2 * nrow(data)))

training <- which(!(seq(nrow(data)) %in% test))

test_data <- data.frame(data[test, ])

training_data <- data.frame(data[training, ])

```

```{r, Linear Regression}

Model_1 <- lm(data = training_data, n_conflict ~.)

# summary(Model_1)

# Model_2 <- lm(data = data[training,], n_conflict ~ year + gdp_current_US + population + population_growth_rate + infant_mortality + hdi + military_spending + freedom_index + EFindex + peace_keeping + fragment + xrcomp + xropen + parreg + parcomp + polity2 + terrorism_kill + terrorism_wound + nonstate_target + state_target)

# summary(Model_2)

# Model_3 <- lm(data = data[training,], n_conflict ~ year + gdp_current_US + population + infant_mortality + hdi + freedom_index + EFindex + fragment + xrcomp + parreg + parcomp + polity2 + terrorism_kill + terrorism_wound + nonstate_target + state_target)

# summary(Model_3)


```

```{r, Prediction Modelling}

predictions <- predict(Model_1, test_data[,-300]) %>%
  round(digits = 0)

predictions[predictions < 0] <- 0

MSE_model_1 <- mean((predictions - test_data[,300])^2)

predictions_data <- data.frame(predictions)


# Here I test the accuracy of how the model predicts the exact 
# number of conflicts. In the next code chunck I check if it 
# can just predict whether a conflict occurs or not. 

table(Truth = test_data$n_conflict, Prediction = predictions_data$predictions)
```

```{r, Accuracy Checking}

check <- data.frame(test_data, predictions_data) 


# Something weird is happening when I un dummy things, but since that step isn't 
# actually necessary I'm going to skip it for now

check2 <- check %>%
  gather(key, value, starts_with("country_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "country"), sep = "_") %>%
  select(-value, -start) %>%
  gather(key, value, starts_with("year_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "year"), sep = "_") %>%
  select(-value, -start) %>%
  gather(key, value, starts_with("continent_")) %>%
  filter(value == 1) %>%
  separate(col = key, into = c("start", "continent"), sep = "_") %>%
  select(-value, -start) %>%
  select(year, country, n_conflict, predictions)


check$real_conflict <- ifelse(check$n_conflict >=1, 1, 0)
check$predict_conflict <- ifelse(check$predictions >= 1, 1, 0)


final_check <- check %>%
  mutate(diff = real_conflict - predict_conflict) %>%
  count(diff)

labels <- c("False Positive", "Accurate", "False Negative")

Percent_Linear <- data.frame(Percent = final_check$n/nrow(test_data)) %>%
  round(digits = 4)

final_check <- data.frame(labels, final_check, Percent_Linear) %>%
  select(-diff)

row1 <- c(NA, NA, NA)
row2 <- c("MSE", unlist(round(MSE_model_1, digits = 4)), NA)

final_check <- rbind(final_check, row1,  row2) 

final_check$Percent <- as.numeric(final_check$Percent)



final_check %>%
  gt() %>%
  cols_label("labels" = " ", "n" = "Value") %>%
  tab_header(
    title = "Predicting Civil Conflict",
    subtitle = "Linear Model Prediction Results "
  ) %>%
  fmt_missing(
    columns = 1:3, 
    missing_text = " "
  ) %>%
  cols_align(align = c("center"), columns = TRUE) %>%
  fmt_percent(
    columns = 3, 
    decimals = 2
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(size = 17), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_column_labels(c("n", "Percent"))
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_body(columns = "labels")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_body(columns = c("n", "Percent"))
  ) 

```

```{r Ridge Regression}


ridge_check <- cv.glmnet(x = as.matrix(data[,1:299]),
                         y = as.numeric(data[,300]), 
                         alpha = 0)

# print(ridge_check$lambda)

# print(round(ridge_check$cvm,4))

opt_lambda <- ridge_check$lambda.min
  
  

ridge_model <- glmnet(x = as.matrix(training_data[,1:299]),
                      y = as.numeric(training_data[,300]), 
                      lambda = opt_lambda, 
                      alpha = 0)

ridge_predictions <- predict(ridge_model, s = opt_lambda, newx = as.matrix(test_data[,1:299]))

MSE_model_2 <- mean((ridge_predictions - test_data[,300])^2)

ridge_predictions_data <- data.frame(ridge_predictions) %>%
  round(digits = 0)

ridge_predictions_data$X1[ridge_predictions_data$X1 < 0] <- 0

ridge_predictions_data$predictions <- ridge_predictions_data$X1

ridge_predictions_data <- ridge_predictions_data %>%
  select(-X1)

table(Truth = test_data$n_conflict, Prediction = ridge_predictions_data$predictions)
```

```{r Ridge Accuracy Check}

ridge_check <- data.frame(test_data, ridge_predictions_data) 


ridge_check$real_conflict <- ifelse(ridge_check$n_conflict >= 1, 1, 0)
ridge_check$predict_conflict <- ifelse(ridge_check$predictions >= 1, 1, 0)


final_ridge_check <- ridge_check %>%
  mutate(diff = real_conflict - predict_conflict) %>%
  count(diff)

final_ridge_check <- data.frame(labels, final_ridge_check)

Percent_Ridge <- data.frame(Percent = final_ridge_check$n/nrow(test_data)) %>%
  round(digits = 4)

final_ridge_check <- data.frame(final_ridge_check, Percent_Ridge) %>%
  select(-diff)

row2_x <- c("MSE", unlist(round(MSE_model_2, digits = 4)), NA)

final_ridge_check <- rbind(final_ridge_check, row1,  row2_x) 

final_ridge_check$Percent <- as.numeric(final_ridge_check$Percent)



final_ridge_check %>%
  gt() %>%
  cols_label("labels" = " ", "n" = "Value") %>%
  tab_header(
    title = "Predicting Civil Conflict",
    subtitle = "Ridge Regression Prediction Results "
  ) %>%
  fmt_missing(
    columns = 1:3, 
    missing_text = " "
  ) %>%
  cols_align(align = c("center"), columns = TRUE) %>%
  fmt_percent(
    columns = 3, 
    decimals = 2
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(size = 17), 
    locations = cells_title(groups = "subtitle")
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_column_labels(c("n", "Percent"))
  ) %>%
  tab_style(
    cell_text(weight = "bold"), 
    locations = cells_body(columns = "labels")
  ) %>%
  tab_style(
    cell_text(style = "italic"), 
    locations = cells_body(columns = c("n", "Percent"))
  ) 
```


